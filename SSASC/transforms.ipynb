{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for computing coordinate transformations, derivatives and\n",
    "sample means of parameters and data.\n",
    "---\n",
    "This code implements approximate inference methods for State-Space Analysis of\n",
    "Spike Correlations (Shimazaki et al. PLoS Comp Bio 2012). It is an extension of\n",
    "the existing code from repository <https://github.com/tomxsharp/ssll> (For\n",
    "Matlab Code refer to <http://github.com/shimazaki/dynamic_corr>). We\n",
    "acknowledge Thomas Sharp for providing the code for exact inference.\n",
    "In this library are additional methods provided to perform the State-Space\n",
    "Analysis approximately. This includes pseudolikelihood, TAP, and Bethe\n",
    "approximations. For details see: <http://arxiv.org/abs/1607.08840>\n",
    "Copyright (C) 2016\n",
    "Authors of the extensions: Christian Donner (christian.donner@bccn-berlin.de)\n",
    "                           Hideaki Shimazaki (shimazaki@brain.riken.jp)\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "import itertools\n",
    "import numpy\n",
    "import pdb\n",
    "from scipy import sparse\n",
    "import import_ipynb\n",
    "\n",
    "\n",
    "# Matrix to map from theta to probability\n",
    "p_map = None\n",
    "# Matrix to map from probability to eta\n",
    "eta_map = None\n",
    "\n",
    "\n",
    "def comb(N, k):\n",
    "    \"\"\"\n",
    "    Compute the combinatorial operator N-choose-k.\n",
    "    :param int N:\n",
    "        Number of things.\n",
    "    :param int k:\n",
    "        Number of elements taken.\n",
    "    :returns:\n",
    "        N-choose-k\n",
    "    \"\"\"\n",
    "    nck = float(numpy.math.factorial(N)) / (float(numpy.math.factorial(k)) * float(numpy.math.factorial((N - k))))\n",
    "    \n",
    "    nck = int( numpy.around( nck ) )\n",
    "\n",
    "    return nck\n",
    "\n",
    "\n",
    "def compute_D(N, O):\n",
    "    \"\"\"\n",
    "    Computes the number of natural parameters for the given number of cells and\n",
    "    order of interactions.\n",
    "    :param int N:\n",
    "        Total cells in the spike data.\n",
    "    :param int order:\n",
    "        Order of spike-train interactions to estimate, for example, 2 =\n",
    "        pairwise, 3 = triplet-wise...\n",
    "    :returns:\n",
    "        Number of natural parameters for the spike-pattern interactions.\n",
    "    \"\"\"\n",
    "    #print(N)\n",
    "    #print([comb(N, k) for k in range(1, O + 1)])\n",
    "    D = int(numpy.sum([comb(N, k) for k in range(1, O + 1)]))\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def compute_eta(p):\n",
    "    \"\"\"\n",
    "    Computes the expected values, eta, of spike patterns\n",
    "        n_0,1 = p(0,1) + p(1,1) # for example\n",
    "    from the supplied probability mass.\n",
    "    :param numpy.ndarray p:\n",
    "        Probability mass of spike patterns.\n",
    "    :returns:\n",
    "        Expected values of spike patterns (eta) as a numpy.ndarray.\n",
    "    \"\"\"\n",
    "    global eta_map\n",
    "\n",
    "    eta = eta_map.dot(p)\n",
    "\n",
    "    return numpy.array(eta)\n",
    "\n",
    "\n",
    "def compute_fisher_info(p, eta):\n",
    "    \"\"\"\n",
    "    Computes the Fisher-information matrix of the expected values, eta, of spike\n",
    "    patterns for the purposes of Newton-Raphson gradient-ascent and\n",
    "    computation of the marginal probability distribution. For example, for two\n",
    "    neurons:\n",
    "        H = [n1 - n1^2,      n12 - n1 * n2,  n12 - n1 * n12,\n",
    "             n12 - n1 * n2,  n2 - n2^2,      n12 - n2 * n12,\n",
    "             n12 - n1 * n12, n12 - n2 * n12, n12 - n12^2]\n",
    "    :param numpy.ndarray p:\n",
    "        Probability mass of spike patterns.\n",
    "    :param numpy.ndarray eta:\n",
    "        Expected values of spike patterns.\n",
    "    :returns:\n",
    "        Fisher-information matrix as a numpy.ndarray.\n",
    "    \"\"\"\n",
    "    global p_map, eta_map\n",
    "\n",
    "    # Stack columns of p for next step\n",
    "    p_stack = numpy.repeat(p, eta.size).reshape(p.size, eta.size)\n",
    "    # Compute Fisher matrix\n",
    "    fisher = eta_map.dot(p_map.multiply(p_stack)) - numpy.outer(eta, eta)\n",
    "\n",
    "    return numpy.array(fisher)\n",
    "\n",
    "\n",
    "def compute_p(theta):\n",
    "    \"\"\"\n",
    "    Computes the probability distribution of spike patterns, for example\n",
    "        p(x1,x2) =     e^(t1x1)e^(t2x2)e^(t12x1x2)\n",
    "                   -----------------------------------\n",
    "                   1 + e^(t1) + e^(t2) + e^(t1+t2+t12)\n",
    "    from the supplied natural parameters.\n",
    "    :param numpy.ndarray theta:\n",
    "        Natural `theta' parameters: t1, t2, ..., t12, ...\n",
    "    :returns:\n",
    "        Probability mass as a numpy.ndarray.\n",
    "    \"\"\"\n",
    "    global p_map\n",
    "\n",
    "    # Compute log probabilities\n",
    "    log_p = p_map.dot(theta)\n",
    "    # Take exponential and normalise\n",
    "    p = numpy.exp(log_p)\n",
    "    p_tmp = p / numpy.sum(p)\n",
    "\n",
    "    return numpy.array(p_tmp, dtype=float)\n",
    "\n",
    "\n",
    "def compute_psi(theta):\n",
    "    \"\"\"\n",
    "    Computes the log normalisation parameter, psi, for the log-linear\n",
    "    probability mass function of spike patterns. For example, for two neurons\n",
    "        psi(theta) = log( 1 + e^(t1) + e^(t2) + e^(t1+t2+t12) )\n",
    "    :param numpy.ndarray theta:\n",
    "        Natural `theta' parameters: t1, t2, ..., t12, ...\n",
    "    :returns:\n",
    "        Normalisation parameter, psi, of the log linear model as a float.\n",
    "    \"\"\"\n",
    "    global p_map\n",
    "\n",
    "    # Take coincident-pattern subsets of theta\n",
    "    tmp = p_map.dot(theta)\n",
    "    # Take the sum of the exponentials and take the log\n",
    "    tmp = numpy.sum(numpy.exp(tmp))\n",
    "    psi = numpy.log(tmp)\n",
    "\n",
    "    return float(psi)\n",
    "\n",
    "\n",
    "def compute_y(spikes, order, window):\n",
    "    \"\"\"\n",
    "    Computes the empirical mean rate of each spike pattern across trials for\n",
    "    each timestep up to `order', for example\n",
    "        y_12,t = 1 / N * \\sigma_{l=1}^{L} X1_l,t * X2_l,t\n",
    "    is a second-order pattern where t is the timestep and l is the trial.\n",
    "    :param numpy.ndarray spikes:\n",
    "        Binary matrix with dimensions (time, runs, cells), in which a `1' in\n",
    "        location (t, r, c) denotes a spike at time t in run r by cell c.\n",
    "    :param int order:\n",
    "        Order of spike-train interactions to estimate, for example, 2 =\n",
    "        pairwise, 3 = triplet-wise...\n",
    "    :param int window:\n",
    "        Bin-width for counting spikes, in milliseconds.\n",
    "    :returns:\n",
    "        Trial-mean rates of each pattern in each timestep, as a numpy.ndarray\n",
    "        with `time' rows and sum_{k=1}^{order} {n \\choose k} columns, given\n",
    "        n cells.\n",
    "    \"\"\"\n",
    "    # Get spike-matrix metadata\n",
    "    T, R, N = spikes.shape\n",
    "    # Bin spikes\n",
    "    spikes = spikes.reshape((int(T / window), int(window), int(R), int(N)))\n",
    "    spikes = spikes.any(axis=1)\n",
    "    # Compute each n-choose-k subset of cell IDs up to `order'\n",
    "    subsets = enumerate_subsets(int(N), order)\n",
    "    # Set up the output array\n",
    "    y = numpy.zeros((int(T / window), len(subsets)))\n",
    "    # Iterate over each subset\n",
    "    for i in range(len(subsets)):\n",
    "        # Select the cells that are in the subset\n",
    "        sp = spikes[:,:,subsets[i]]\n",
    "        # Find the timesteps in which all subset-cells spike coincidentally\n",
    "        spc = sp.sum(axis=2) == len(subsets[i])\n",
    "        # Average the occurences of coincident patterns to get the mean rate\n",
    "        y[:,i] = spc.mean(axis=1)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def enumerate_subsets(N, O):\n",
    "    \"\"\"\n",
    "    Enumerates all N-choose-k subsets of cell IDs for k = 1, 2, ..., O. For\n",
    "    example,\n",
    "        >>> compute_subsets(4, 2)\n",
    "        >>> [(0,), (1,), (2,), (3,), (0, 1),\n",
    "                (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "    :param int N:\n",
    "        Total cells from which to choose subsets.\n",
    "    :param int O:\n",
    "        Maximum size of subsets to enumerate.\n",
    "    :returns:\n",
    "        List of tuples, each tuple containing a subset of cell IDs.\n",
    "    \"\"\"\n",
    "    # Compute each C-choose-k subset of cell IDs up to `O'\n",
    "    subsets = list()\n",
    "    ids = numpy.arange(N)\n",
    "    for k in range(1, O + 1):\n",
    "        subsets.extend(list(itertools.combinations(ids, k)))\n",
    "    # Assert that we've got the correct number of subsets\n",
    "    #print(len(subsets))\n",
    "    #print(compute_D(N, O))\n",
    "\n",
    "    #assert len(subsets) == compute_D(N, O)\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "\n",
    "def enumerate_patterns(N):\n",
    "    \"\"\"\n",
    "    Enumerates all spike patterns in order, for example:\n",
    "        >>> enumerate_patterns(3)\n",
    "        array([[0, 0, 0],\n",
    "               [1, 0, 0],\n",
    "               [0, 1, 0],\n",
    "               [0, 0, 1],\n",
    "               [1, 1, 0],\n",
    "               [1, 0, 1],\n",
    "               [0, 1, 1],\n",
    "               [1, 1, 1]], dtype=uint8)\n",
    "    :param int N:\n",
    "        Number of cells for which to enumerate patterns.\n",
    "    :returns:\n",
    "        Binary matrix of spike patterns as a numpy.ndarray of dimensions\n",
    "        (2**N, N).\n",
    "    \"\"\"\n",
    "    # Get the spike patterns as ordered subsets\n",
    "    subsets = enumerate_subsets(N, N)\n",
    "    #assert len(subsets) == 2**N - 1\n",
    "    # Generate output array and fill according to subsets\n",
    "    fx = numpy.zeros((2**N, N), dtype=numpy.uint8)\n",
    "    for i in range(len(subsets)):\n",
    "        fx[i+1,subsets[i]] = 1\n",
    "    \n",
    "    return fx\n",
    "\n",
    "\n",
    "def initialise(N, O):\n",
    "    \"\"\"\n",
    "    Sets up matrices to transform between theta, probability and eta\n",
    "    coordinates. Computing probability requires finding subsets of theta for the\n",
    "    numerator; for example, with two cells, finding the numerator:\n",
    "        p(x1,x2) =     e^(t1x1)e^(t2x2)e^(t12x1x2)\n",
    "                   -----------------------------------\n",
    "                   1 + e^(t1) + e^(t2) + e^(t1+t2+t12)\n",
    "    We calculate a `p_map' to do this for arbitrary numbers of neurons and\n",
    "    orders of interactions. To compute from probabilities to eta coordinates,\n",
    "    we use an `eta_map' that is just the transpose of the `p_map'. The method\n",
    "    for doing this is a bit tricky, and not easy to explain. Suffice to say,\n",
    "    it produces to the correct maps.\n",
    "    This function has the side effect of setting global variables `p_map' and\n",
    "    `eta_map', which are used later by other functions in this module.\n",
    "    :param int N:\n",
    "        Total cells in the spike data.\n",
    "    :param int order:\n",
    "        Order of spike-train interactions to estimate, for example, 2 =\n",
    "        pairwise, 3 = triplet-wise...\n",
    "    \"\"\"\n",
    "    global p_map, eta_map\n",
    "\n",
    "    # Create a matrix of binary spike patterns\n",
    "    fx = enumerate_patterns(N)\n",
    "    # Compute the number of natural parameters, given the order parameter\n",
    "    D = compute_D(N, O)\n",
    "    # Set up the output matrix\n",
    "    p_map = numpy.ones((2**N, D), dtype=numpy.uint8)\n",
    "    # Compute the map!\n",
    "    for i in range(1, D+1):\n",
    "        idx = numpy.nonzero(fx[i,:])[0]\n",
    "        for j in range(idx.size):\n",
    "            p_map[:,i-1] = p_map[:,i-1] & fx[:,idx[j]]\n",
    "    # Set up the eta map\n",
    "    p_map = sparse.csc_matrix(p_map)\n",
    "    eta_map = p_map.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
