{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classes for encapsulating data used in the expectation maximisation algorithm.\n",
    "Changes to the original code to incorporate approximations\n",
    "---\n",
    "This code implements approximate inference methods for State-Space Analysis of\n",
    "Spike Correlations (Shimazaki et al. PLoS Comp Bio 2012). It is an extension of\n",
    "the existing code from repository <https://github.com/tomxsharp/ssll> (For\n",
    "Matlab Code refer to <http://github.com/shimazaki/dynamic_corr>). We\n",
    "acknowledge Thomas Sharp for providing the code for exact inference.\n",
    "In this library are additional methods provided to perform the State-Space\n",
    "Analysis approximately. This includes pseudolikelihood, TAP, and Bethe\n",
    "approximations. For details see: <http://arxiv.org/abs/1607.08840>\n",
    "Copyright (C) 2016\n",
    "Authors of the extensions: Christian Donner (christian.donner@bccn-berlin.de)\n",
    "                           Hideaki Shimazaki (shimazaki@brain.riken.jp)\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "import numpy\n",
    "import pdb\n",
    "\n",
    "import import_ipynb\n",
    "import transforms\n",
    "import mean_field\n",
    "import pseudo_likelihood\n",
    "import bethe_approximation\n",
    "import max_posterior\n",
    "import probability\n",
    "\n",
    "\n",
    "class EMData:\n",
    "    \"\"\"\n",
    "    Contains all of the data used by the EM algorithm, purely for convenience.\n",
    "    Takes spike trains as an input and computes the observable spike\n",
    "    (co)incidences (patterns). Initialises the means and covariances of the\n",
    "    filtered- smoothed- and one-step-prediction natural-parameter distributions.\n",
    "    Initialises the autoregressive and state-transition hyperparameters.\n",
    "    :param numpy.ndarray spikes:\n",
    "        Binary matrix with dimensions (time, runs, cells), in which a `1' in\n",
    "        location (t, r, c) denotes a spike at time t in run r by cell c.\n",
    "    :param int order:\n",
    "        Order of spike-train interactions to estimate, for example, 2 =\n",
    "        pairwise, 3 = triplet-wise...\n",
    "    :param int window:\n",
    "        Bin-width for counting spikes, in milliseconds.\n",
    "    :param str param_est:\n",
    "        Parameter whether exact likelihood ('exact') or pseudo likelihood\n",
    "        ('pseudo') should be used\n",
    "    :param str param_est_eta:\n",
    "        Eta parameters are either calculated exactly ('exact'), by mean\n",
    "        field TAP approximation ('TAP'), or Bethe approximation (belief\n",
    "        propagation-'bethe_BP', CCCP-'bethe_CCCP', hybrid-'bethe_hybrid')\n",
    "    :param function map_function:\n",
    "        A function from max_posterior.py or pseudo_likelihood.py\n",
    "        that returns an estimate of the posterior distribution of natural\n",
    "        parameters for a given timestep.\n",
    "    :param float lmbda1:\n",
    "        Inverse coefficient on the identity matrix of the initial\n",
    "        state-transition covariance matrix for the first order theta parameters.\n",
    "    :param float lmbda2:\n",
    "        Inverse coefficient on the identity matrix of the initial\n",
    "        state-transition covariance matrix for the second order theta parameters.\n",
    "    :ivar numpy.ndarray spikes:\n",
    "        Reference to the input spikes.\n",
    "    :ivar int order:\n",
    "        Copy of the `order' parameter.\n",
    "    :ivar int window:\n",
    "        Copy of the `window' parameter.\n",
    "    :ivar function max_posterior:\n",
    "        A function from max_posterior.py that returns an estimate of the\n",
    "        posterior distribution of natural parameters for a given timestep.\n",
    "    :ivar function  marg_llk:\n",
    "        A function that returns the marginal log-likelihood or pseudo-log-\n",
    "        likelihood.\n",
    "    :ivar int T:\n",
    "        Number of timestep in the pattern-counts; should equal the length of the\n",
    "        spike trains divided by the window.\n",
    "    :ivar int R:\n",
    "        Number of trials in the `spikes' input.\n",
    "    :ivar int N:\n",
    "        Number of cells in the `spikes' input.\n",
    "    :ivar int D:\n",
    "        Dimensions of the natural-parameter distributions, equal to\n",
    "        D = sum_{k=1}^{`order'} {`N' \\choose k}. Density means are all of\n",
    "        shape (T, D, 1), covariances are (T, D, D) and hyperparameters are\n",
    "        (D, D).\n",
    "    :ivar numpy.ndarray y:\n",
    "        Mean rates of each spike pattern at each timestep, in a 2D array of\n",
    "        dimesions (T, D).\n",
    "    :ivar numpy.ndarray theta_o:\n",
    "        One-step-prediction density mean. Data at theta_o[0] describes the\n",
    "        probability of the initial state.\n",
    "    :ivar numpy.ndarray theta_f:\n",
    "        Filtered density mean.\n",
    "    :ivar numpy.ndarray theta_s:\n",
    "        Smoothed density mean.\n",
    "    :ivar numpy.ndarray eta:\n",
    "        Estimates rate (conditional rate for pseudo likelihood).\n",
    "    :ivar numpy.ndarray sigma_o:\n",
    "        One-step-prediction density covariance.\n",
    "    :ivar numpy.ndarray sigma_o_inv:\n",
    "        Inverse of one-step-prediction density covariance\n",
    "    :ivar numpy.ndarray sigma_f:\n",
    "        Filtered density covariance.\n",
    "    :ivar numpy.ndarray sigma_s:\n",
    "        Smoothed density covariance.\n",
    "    :ivar numpy.ndarray sigma_s_lag\n",
    "        Smoothed density lag-one covariance.\n",
    "    :ivar numpy.ndarray F:\n",
    "        Autoregressive parameter of state transitions.\n",
    "    :ivar numpy.ndarray Q:\n",
    "        Covariance matrix of state-transition probability.\n",
    "    :ivar int iterations:\n",
    "        Number of EM iterations for which the algorithm ran.\n",
    "    :ivar float convergence:\n",
    "        Ratio between previous and current log-marginal prob. on last iteration.\n",
    "    \"\"\"\n",
    "    def __init__(self, spikes, order, window, param_est, param_est_eta, map_function,\n",
    "                 lmbda1, lmbda2):\n",
    "\n",
    "        # Record the input parameters\n",
    "        self.spikes, self.order, self.window = spikes, order, window\n",
    "        T, self.R, self.N = self.spikes.shape\n",
    "        if param_est == 'exact':\n",
    "            transforms.initialise(self.N, self.order)\n",
    "            self.max_posterior = max_posterior.functions[map_function]\n",
    "        elif param_est == 'pseudo':\n",
    "            pseudo_likelihood.compute_Fx_s(self.spikes, self.order)\n",
    "            self.max_posterior = pseudo_likelihood.functions[map_function]\n",
    "\n",
    "        self.param_est_theta = param_est\n",
    "        self.param_est_eta = param_est_eta\n",
    "\n",
    "        self.marg_llk = log_marginal_functions[param_est_eta]\n",
    "        # Compute the `sample' spike-train interactions from the input spikes\n",
    "        self.y = transforms.compute_y(self.spikes, self.order, self.window)\n",
    "        # Count timesteps, trials, cells and interaction dimensions\n",
    "\n",
    "        self.T, self.D = self.y.shape\n",
    "        assert self.T == T / window\n",
    "        # Initialise one-step-prediction- filtered- smoothed-density means\n",
    "        self.theta_o = numpy.zeros((self.T,self.D))\n",
    "        self.theta_f = numpy.zeros((self.T,self.D))\n",
    "        self.theta_s = numpy.zeros((self.T,self.D))\n",
    "\n",
    "\n",
    "        # Initialise covariances of the same (an I-matrix for each timestep)\n",
    "        if param_est == 'exact':\n",
    "            I = [numpy.identity(self.D) for i in range(self.T)]\n",
    "            I = numpy.vstack(I).reshape((self.T,self.D,self.D))\n",
    "            self.sigma_o = .1 * I\n",
    "            self.sigma_o_inv = 1./.1 * I\n",
    "            del I\n",
    "            # Intialise autoregressive and transition probability hyperparameters\n",
    "            self.sigma_f = numpy.copy(self.sigma_o)\n",
    "            self.sigma_s = numpy.copy(self.sigma_o)\n",
    "            self.sigma_s_lag = numpy.copy(self.sigma_o)\n",
    "        # For approximate term initialize only the diagonal of the convariances\n",
    "        else:\n",
    "            self.sigma_o = .1*numpy.ones((self.T,self.D))\n",
    "            self.sigma_o_inv = 1./.1*numpy.ones((self.T,self.D))\n",
    "            self.sigma_f = .1*numpy.ones((self.T,self.D))\n",
    "            self.sigma_s = .1*numpy.ones((self.T,self.D))\n",
    "            self.sigma_s_lag = .1*numpy.ones((self.T,self.D))\n",
    "        self.F = numpy.identity(self.D)\n",
    "        self.Q = numpy.zeros([self.D, self.D])\n",
    "        self.Q[:self.N, :self.N] = 1. / lmbda1 * numpy.identity(self.N)\n",
    "        self.Q[self.N:, self.N:] = 1. / lmbda2 * numpy.identity(self.D - self.N)\n",
    "        self.mllk = numpy.inf\n",
    "        # Metadata about EM algorithm execution\n",
    "        self.iterations, self.convergence = 0, numpy.inf\n",
    "\n",
    "# Different approximations of the marginal log likelihood\n",
    "log_marginal_functions = {'exact': probability.log_marginal,\n",
    "                          'mf': mean_field.log_marginal,\n",
    "                          'bethe_BP': bethe_approximation.log_marginal_BP,\n",
    "                          'bethe_CCCP': bethe_approximation.log_marginal_CCCP,\n",
    "                          'bethe_hybrid': bethe_approximation.log_marginal_hybrid}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
