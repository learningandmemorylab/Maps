{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some useful functions.\n",
    "---\n",
    "This code implements approximate inference methods for State-Space Analysis of\n",
    "Spike Correlations (Shimazaki et al. PLoS Comp Bio 2012). It is an extension of\n",
    "the existing code from repository <https://github.com/tomxsharp/ssll> (For\n",
    "Matlab Code refer to <http://github.com/shimazaki/dynamic_corr>). We\n",
    "acknowledge Thomas Sharp for providing the code for exact inference.\n",
    "In this library are additional methods provided to perform the State-Space\n",
    "Analysis approximately. This includes pseudolikelihood, TAP, and Bethe\n",
    "approximations. For details see: <http://arxiv.org/abs/1607.08840>\n",
    "Copyright (C) 2016\n",
    "Authors of the extensions: Christian Donner (christian.donner@bccn-berlin.de)\n",
    "                           Hideaki Shimazaki (shimazaki@brain.riken.jp)\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "import numpy\n",
    "import import_ipynb\n",
    "import mean_field\n",
    "import synthesis\n",
    "import transforms\n",
    "\n",
    "\n",
    "def get_energies(emd):\n",
    "    \"\"\" Wrapper function to get all energies.\n",
    "    :param ssll.container emd:\n",
    "        ssll-container object for that energies should be computed\n",
    "    \"\"\"\n",
    "    N, O = emd.N, emd.order\n",
    "    theta = emd.theta_s\n",
    "    eta, emd.eta_sampled = compute_eta(theta, N, O)\n",
    "    psi, emd.psi_sampled = compute_psi(theta, N, O)\n",
    "    eta1 = eta[:,:N]\n",
    "    theta1 = compute_ind_theta(eta1)\n",
    "    psi1 = compute_ind_psi(theta1)\n",
    "    emd.U1 = compute_internal_energy(theta1, eta1)\n",
    "    emd.S1 = compute_entropy(theta1, eta1, psi1, 1)\n",
    "    emd.eta = eta\n",
    "    emd.psi = psi\n",
    "    emd.U2 = compute_internal_energy(theta, eta)\n",
    "    emd.S2 = compute_entropy(theta, eta, psi, 2)\n",
    "    emd.S_ratio = (emd.S1 - emd.S2)/emd.S1\n",
    "    emd.dkl = compute_dkl(eta, emd.theta_s, psi, theta1, psi1, N)\n",
    "    emd.llk1 = compute_likelihood(emd.y[:,:N], theta1, psi1, emd.R)\n",
    "    emd.llk2 = compute_likelihood(emd.y, theta, psi, emd.R)\n",
    "\n",
    "\n",
    "def compute_ind_eta(theta):\n",
    "    \"\"\" Computes analytically eta from theta for independent model.\n",
    "    :param numpy.ndarray theta:\n",
    "        (t, c) array with natural parameters\n",
    "    :return numpy.ndarray:\n",
    "        (t, c) array with expectation parameters parameters\n",
    "    \"\"\"\n",
    "    eta = 1./(1. + numpy.exp(-theta))\n",
    "    return eta\n",
    "\n",
    "\n",
    "def compute_ind_theta(eta):\n",
    "    \"\"\" Computes analytically theta from eta for independent model.\n",
    "    :param numpy.ndarray eta:\n",
    "        (t, c) array with expectation parameters\n",
    "    :return numpy.ndarray:\n",
    "        (t, c) array with natural parameters parameters\n",
    "    \"\"\"\n",
    "    theta = numpy.log(eta/(1. - eta))\n",
    "    return theta\n",
    "\n",
    "\n",
    "def compute_ind_psi(theta):\n",
    "    \"\"\" Computes analytically psi from theta for independent model.\n",
    "    :param numpy.ndarray theta:\n",
    "        (t, c) array with natural parameters\n",
    "    :return numpy.ndarray:\n",
    "        (t,) with solution for log-partition function\n",
    "    \"\"\"\n",
    "    return numpy.sum(numpy.log(1. + numpy.exp(theta)), axis=1)\n",
    "\n",
    "\n",
    "def compute_eta(theta, N, O, R=1000):\n",
    "    \"\"\" Computes eta from given theta.\n",
    "    :param numpy.ndarray theta:\n",
    "        (t, d) array with natural parameters\n",
    "    :param int N:\n",
    "        number of cells\n",
    "    :param int O:\n",
    "        order of model\n",
    "    :param int R:\n",
    "        trials that should be sampled to estimate eta\n",
    "    :return numpy.ndarray, list:\n",
    "        (t, d) array with natural parameters parameters and a list with indices of bins, for which has been sampled\n",
    "    Details: Tries to estimate eta by solving the forward problem from TAP. However, if it fails we fall back to\n",
    "    sampling. For networks with less then 15 neurons exact solution is computed and for first order analytical solution\n",
    "    is used.\n",
    "    \"\"\"\n",
    "    T, D = theta.shape\n",
    "    eta = numpy.empty(theta.shape)\n",
    "    bins_to_sample = []\n",
    "    if O == 1:\n",
    "        eta = compute_ind_eta(theta[:,:N])\n",
    "    elif O == 2:\n",
    "        # if few cells compute exact rates\n",
    "        if N > 15:\n",
    "            for i in range(T):\n",
    "                # try to solve forward problem\n",
    "                try:\n",
    "                    eta[i] = mean_field.forward_problem(theta[i], N, 'TAP')\n",
    "                # if it fails remember bin for sampling\n",
    "                except Exception:\n",
    "                    bins_to_sample.append(i)\n",
    "            if len(bins_to_sample) != 0:\n",
    "                theta_to_sample = numpy.empty([len(bins_to_sample), D])\n",
    "                for idx, bin2sampl in enumerate(bins_to_sample):\n",
    "                    theta_to_sample[idx] = theta[bin2sampl]\n",
    "                spikes = synthesis.generate_spikes_gibbs_parallel(theta_to_sample, N, O, R, sample_steps=100)\n",
    "                eta_from_sample = transforms.compute_y(spikes, O, 1)\n",
    "                for idx, bin2sampl in enumerate(bins_to_sample):\n",
    "                    eta[bin2sampl] = eta_from_sample[idx]\n",
    "\n",
    "        # if large ensemble approximate\n",
    "        else:\n",
    "            transforms.initialise(N, O)\n",
    "            for i in range(T):\n",
    "                p = transforms.compute_p(theta[i])\n",
    "                eta[i] = transforms.compute_eta(p)\n",
    "\n",
    "    return eta, bins_to_sample\n",
    "\n",
    "\n",
    "def compute_psi(theta, N, O, R=1000):\n",
    "    \"\"\" Computes psi from given theta.\n",
    "    :param numpy.ndarray theta:\n",
    "        (t, d) array with natural parameters\n",
    "    :param int N:\n",
    "        number of cells\n",
    "    :param int O:\n",
    "        order of model\n",
    "    :param int R:\n",
    "        trials that should be sampled to estimate eta\n",
    "    :return numpy.ndarray, list:\n",
    "        (t, d) array with log-partition and a list with indices of bins, for which has been sampled\n",
    "    For first order the analytical solution is used. For networks with 15 units and less the exact solution is computed.\n",
    "    Otherwise, the Ogata-Tanemura-Estimator is used. It tries to solve the forward problem and samples where it fails.\n",
    "    \"\"\"\n",
    "    T = theta.shape[0]\n",
    "    bins_sampled = []\n",
    "    psi = numpy.empty(T)\n",
    "\n",
    "    if O == 1:\n",
    "        psi = compute_ind_psi(theta[:,:N])\n",
    "    if O == 2:\n",
    "        # if few cells compute exact result\n",
    "        if N > 15:\n",
    "            theta0 = numpy.copy(theta)\n",
    "            theta0[:,N:] = 0\n",
    "            psi0 = compute_ind_psi(theta0[:,:N])\n",
    "            for i in range(T):\n",
    "                psi[i], sampled = ot_estimator(theta0[i], psi0[i], theta[i], N, O, N)\n",
    "                # save bin if sampled\n",
    "                if sampled:\n",
    "                    bins_sampled.append(i)\n",
    "        # else approximate\n",
    "        else:\n",
    "            transforms.initialise(N, 2)\n",
    "            for i in range(T):\n",
    "                psi[i] = transforms.compute_psi(theta[i])\n",
    "    return psi, bins_sampled\n",
    "\n",
    "\n",
    "def ot_estimator(th0, psi0, th1, N, O, K, expansion='TAP'):\n",
    "    \"\"\" Uses the Ogata-Tanemura Estimator for estimation (Huang, 2001)\n",
    "    :param numpy.ndarray th0:\n",
    "        (1,d) array with theta distribution where psi is known\n",
    "    :param float psi0\n",
    "        psi corresponding to th0\n",
    "    :param th1:\n",
    "        thetas for which one wants to compute psi\n",
    "    :param int N:\n",
    "        number of cells\n",
    "    :param int O:\n",
    "        order of interactions\n",
    "    :param int K:\n",
    "        points of integration\n",
    "    :returns\n",
    "        estimation of psi to th1\n",
    "    Tries to solve the forward problem at each point and samples if it fails.\n",
    "    \"\"\"\n",
    "\n",
    "    # compute difference between th0 and th1\n",
    "    dth = th1 - th0\n",
    "    # points of integration\n",
    "    int_points = numpy.linspace(0,1,K)\n",
    "    # array for negative derivatives of Energy function\n",
    "    avg_dUs = numpy.empty(K)\n",
    "    # iterate over all integration points\n",
    "    # iterate over all integration points\n",
    "    points_to_sample = []\n",
    "    for i, int_point in enumerate(int_points):\n",
    "        # theta point that needs to be evaluated\n",
    "        th_tmp = th0 + int_point*dth\n",
    "        # Sample Data\n",
    "        eta = mean_field.forward_problem_hessian(th_tmp, N)\n",
    "        # negative derivative of energy function\n",
    "        dU = numpy.dot(dth, eta)\n",
    "        # compute mean\n",
    "        avg_dUs[i] = numpy.mean(dU)\n",
    "\n",
    "    # weights for trapezoidal intergration rule\n",
    "    w = numpy.ones(K)/K\n",
    "    w[0] /= K\n",
    "    w[-1] /= K\n",
    "    # compute estimation of psi\n",
    "    return psi0 + numpy.dot(w, avg_dUs)\n",
    "\n",
    "\n",
    "def compute_internal_energy(theta, eta):\n",
    "    \"\"\" Computes the internal energy of the system.\n",
    "    :param numpy.ndarray theta:\n",
    "        (t, d) array with natural parameters\n",
    "    :param numpy.ndarray eta:\n",
    "        (t, d) array with expectation parameters\n",
    "    :return numpy.ndarray:\n",
    "        (t,) array with internal energy at each time bin\n",
    "    \"\"\"\n",
    "    U = -numpy.sum(theta*eta, axis=1)\n",
    "    return U\n",
    "\n",
    "\n",
    "def compute_entropy(theta, eta, psi, O):\n",
    "    \"\"\" Computes the entropy of the system.\n",
    "    :param numpy.ndarray theta:\n",
    "        (t, d) array with natural parameters\n",
    "    :param numpy.ndarray eta:\n",
    "        (t, d) array with expectation parameters\n",
    "    :param numpy.ndarray psi:\n",
    "        (t,) array with log-partition function\n",
    "    :param int O:\n",
    "        order of model\n",
    "    :return numpy.ndarray:\n",
    "        (t,) array with entropy at each time bin\n",
    "    \"\"\"\n",
    "\n",
    "    if O == 1:\n",
    "        S = -numpy.sum(eta*numpy.log(eta) + (1 - eta)*numpy.log(1 - eta), axis=1)\n",
    "    else:\n",
    "        U = compute_internal_energy(theta, eta)\n",
    "        F = -psi\n",
    "        S = U - F\n",
    "\n",
    "    return S\n",
    "\n",
    "def compute_dkl(eta2, theta2, psi2, theta1, psi1, N):\n",
    "    \"\"\" Computes Kullback Leibler Divergence between pairwise and independent\n",
    "    model.\n",
    "    :param numpy.ndarray eta2:\n",
    "        (t, d) array containing expectations of the pairwise model.\n",
    "    :param numpy.ndarray  theta2:\n",
    "        (t,d) array containing theta parameters of the pairwise model\n",
    "    :param numpy.ndarray  psi2:\n",
    "        (t) array containing the log partition values of pairwise model.\n",
    "    :param numpy.ndarray  theta1:\n",
    "        (t,c) array containing theta parameters of the independent model\n",
    "    :param numpy.ndarray  psi1:\n",
    "        (t) array containing log partition values for the independent model\n",
    "    :param int N:\n",
    "        number of cells\n",
    "    :return:\n",
    "        (t) array with Kullback Leibler Divergen\n",
    "    \"\"\"\n",
    "    dtheta = numpy.copy(theta2)\n",
    "    dtheta[:,:N] = theta2[:,:N] - theta1\n",
    "    dkl = numpy.sum(eta2*dtheta, axis=1) - (psi2 - psi1)\n",
    "    return dkl\n",
    "\n",
    "def compute_likelihood(y, theta, psi, R):\n",
    "    \"\"\" Computes the likelihood of data for a model\n",
    "    :param numpy.ndarray y:\n",
    "        (t,d) array containing empirical expectations of data\n",
    "    :param numpy.ndarray theta:\n",
    "        (t,d) array containing theta parameters of model\n",
    "    :param numpy.ndarray psi:\n",
    "        (t) array of log partition function\n",
    "    :param int R:\n",
    "        number of trials\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    llk = R*(numpy.sum(y*theta, axis=1) - psi)\n",
    "    return llk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
