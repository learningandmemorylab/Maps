{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for performing the expectation maximisation algorithm over the\n",
    "observed spike-pattern rates and the natural parameters. These functions\n",
    "use 'call by reference' in that, rather than returning a result, they update\n",
    "the data referred to by their parameters.\n",
    "---\n",
    "This code implements approximate inference methods for State-Space Analysis of\n",
    "Spike Correlations (Shimazaki et al. PLoS Comp Bio 2012). It is an extension of\n",
    "the existing code from repository <https://github.com/tomxsharp/ssll> (For\n",
    "Matlab Code refer to <http://github.com/shimazaki/dynamic_corr>). We\n",
    "acknowledge Thomas Sharp for providing the code for exact inference.\n",
    "In this library are additional methods provided to perform the State-Space\n",
    "Analysis approximately. This includes pseudolikelihood, TAP, and Bethe\n",
    "approximations. For details see: <http://arxiv.org/abs/1607.08840>\n",
    "Copyright (C) 2016\n",
    "Authors of the extensions: Christian Donner (christian.donner@bccn-berlin.de)\n",
    "                           Hideaki Shimazaki (shimazaki@brain.riken.jp)\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "import numpy\n",
    "import pdb\n",
    "\n",
    "import import_ipynb\n",
    "import probability\n",
    "import transforms\n",
    "import max_posterior\n",
    "\n",
    "\n",
    "CONVERGED = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "def e_step(emd):\n",
    "    \"\"\"\n",
    "    Computes the posterior (approximated as a multivariate Gaussian\n",
    "    distribution) of the natural parameters of observed spike patterns, given\n",
    "    the state-transition hyperparameters. Firstly performs a `forward'\n",
    "    iteration, in which the filter posterior density at time t is determined\n",
    "    from the observed patterns at time t and the one-step prediction density at\n",
    "    time t-1. Secondly performs a `backward' iteration, in which these\n",
    "    sequential filter estimates are smoothed over time.\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    \"\"\"\n",
    "    # Compute the 'forward' filter density\n",
    "    e_step_filter(emd)\n",
    "    # Compute the 'backward' smooth density\n",
    "    e_step_smooth(emd)\n",
    "\n",
    "\n",
    "def e_step_filter(emd):\n",
    "    \"\"\"\n",
    "    Computes the one-step-prediction density and the filter density in the\n",
    "    expectation step.\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    \"\"\"\n",
    "    # Iterate forwards over each timestep, computing filter density\n",
    "    emd.theta_f[0,:], emd.sigma_f[0,:] = max_posterior.run(emd, 0)\n",
    "    for i in range(1, emd.T):\n",
    "        # Compute one-step prediction density\n",
    "        emd.theta_o[i,:] = numpy.dot(emd.F, emd.theta_f[i-1,:])\n",
    "        # Computation for exact case with full covariance matrix\n",
    "        if emd.param_est_eta == 'exact':\n",
    "            tmp = numpy.dot(emd.F, emd.sigma_f[i-1,:,:])\n",
    "            emd.sigma_o[i,:,:] = numpy.dot(tmp, emd.F.T) + emd.Q\n",
    "            # Compute inverse of one-step prediction covariance\n",
    "            emd.sigma_o_inv[i,:,:] = numpy.linalg.inv(emd.sigma_o[i,:,:])\n",
    "        # Computation for approximate case with diagonal covariance matrix\n",
    "        else:\n",
    "            emd.sigma_o[i,:] = emd.sigma_f[i-1,:] + emd.Q.diagonal()\n",
    "            emd.sigma_o_inv[i] = 1./emd.sigma_o[i]\n",
    "        # Get MAP estimate of filter density\n",
    "        emd.theta_f[i,:], emd.sigma_f[i,:] = max_posterior.run(emd, i)\n",
    "\n",
    "\n",
    "def e_step_smooth(emd):\n",
    "    \"\"\"\n",
    "    Computes smooth density in the expectation step.\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    \"\"\"\n",
    "    # Initialise the smoothed theta and sigma values\n",
    "    emd.theta_s[-1] = emd.theta_f[-1]\n",
    "    emd.sigma_s[-1] = emd.sigma_f[-1]\n",
    "    if emd.param_est_eta == 'exact':\n",
    "        # Iterate backwards over each timestep, computing smooth density\n",
    "        for i in reversed(range(emd.T - 1)):\n",
    "            # Compute the A matrix\n",
    "            a = numpy.dot(emd.sigma_f[i], emd.F.T)\n",
    "            A = numpy.dot(a, emd.sigma_o_inv[i+1])\n",
    "            # Compute the backward-smoothed means\n",
    "            tmp = numpy.dot(A, emd.theta_s[i+1,:] - emd.theta_o[i+1,:])\n",
    "            emd.theta_s[i,:] = emd.theta_f[i,:] + tmp\n",
    "            # Compute the backward-smoothed covariances\n",
    "            tmp = numpy.dot(A, emd.sigma_s[i+1] - emd.sigma_o[i+1])\n",
    "            tmp = numpy.dot(tmp, A.T)\n",
    "            emd.sigma_s[i] = emd.sigma_f[i] + tmp\n",
    "            # Compute the backward-smoothed lag-one covariances\n",
    "            emd.sigma_s_lag[i+1] = numpy.dot(A, emd.sigma_s[i+1,:])\n",
    "    else:\n",
    "        for i in reversed(range(emd.T - 1)):\n",
    "            # Compute the A matrix\n",
    "            a = numpy.dot(numpy.diag(emd.sigma_f[i]), emd.F.T)\n",
    "            A = numpy.dot(a, numpy.diag(emd.sigma_o_inv[i+1]))\n",
    "            # Compute the backward-smoothed means\n",
    "            tmp = numpy.dot(A, emd.theta_s[i+1,:] - emd.theta_o[i+1,:])\n",
    "            emd.theta_s[i,:] = emd.theta_f[i,:] + tmp\n",
    "            # Compute the backward-smoothed covariances\n",
    "            tmp = numpy.dot(A, numpy.diag(emd.sigma_s[i+1] - emd.sigma_o[i+1]))\n",
    "            tmp = numpy.dot(tmp, A.T)\n",
    "            emd.sigma_s[i] = numpy.diagonal(numpy.diag(emd.sigma_f[i]) + tmp)\n",
    "            # Compute the backward-smoothed lag-one covariances\n",
    "            emd.sigma_s_lag[i+1] = numpy.dot(A, numpy.diag(emd.sigma_s[i+1])).diagonal()\n",
    "\n",
    "\n",
    "def m_step(emd, stationary='None'):\n",
    "    \"\"\"\n",
    "    Computes the optimised hyperparameters of the natural parameters of the\n",
    "    posterior distributions over time. `Q' is the covariance matrix of the\n",
    "    transition probability distribution. `F' is the autoregressive parameter of\n",
    "    the state transitions, but it is kept constant in this implementation.\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    :param stationary:\n",
    "        If 'all' stationary on all thetas is assumed.\n",
    "    \"\"\"\n",
    "    # Update the initial mean of the one-step-prediction density\n",
    "    emd.theta_o[0, :] = emd.theta_s[0, :]\n",
    "    # Compute the state-transition hyperparameter\n",
    "    m_step_Q(emd, stationary)\n",
    "    #m_step_F(emd)\n",
    "\n",
    "\n",
    "def m_step_F(emd):\n",
    "    \"\"\"\n",
    "    Computes the optimised autogregressive hyperparameter `F' of the natural\n",
    "    parameters of the posterior distributions over time. See equation 39 of\n",
    "    the source paper for details.\n",
    "    NB: This function is not called in this implementation because the\n",
    "    autoregressive parameter is kept constant.\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    \"\"\"\n",
    "    # Set up temporary-results arrays\n",
    "    a = numpy.zeros((emd.D, emd.D))\n",
    "    b = numpy.zeros((emd.D, emd.D))\n",
    "    # Sum partial results over each timestep\n",
    "    for i in range(1, emd.T):\n",
    "        a += emd.sigma_s_lag[i,:,:] +\\\n",
    "             numpy.outer(emd.theta_s[i,:], emd.theta_s[i-1,:])\n",
    "        b += emd.sigma_s[i-1,:,:] +\\\n",
    "             numpy.outer(emd.theta_s[i-1,:], emd.theta_s[i-1,:])\n",
    "    # Dot the results\n",
    "    emd.F = numpy.dot(a, numpy.linalg.inv(b))\n",
    "\n",
    "\n",
    "def m_step_Q(emd, stationary):\n",
    "    \"\"\"\n",
    "    Computes the optimised state-transition covariance hyperparameters `Q' of\n",
    "    the natural parameters of the posterior distributions over time. Here\n",
    "    just one single scalar is considered\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    :param stationary:\n",
    "        If 'all' stationary on all thetas is assumed.\n",
    "    \"\"\"\n",
    "    inv_lmbda = 0\n",
    "    if emd.param_est_eta == 'exact':\n",
    "        for i in range(1, emd.T):\n",
    "            lag_one_covariance = emd.sigma_s_lag[i, :, :]\n",
    "            tmp = emd.theta_s[i, :] - emd.theta_s[i - 1, :]\n",
    "            inv_lmbda += numpy.trace(emd.sigma_s[i, :, :]) - \\\n",
    "                         2 * numpy.trace(lag_one_covariance) + \\\n",
    "                         numpy.trace(emd.sigma_s[i - 1, :, :]) + \\\n",
    "                         numpy.dot(tmp, tmp)\n",
    "        emd.Q = inv_lmbda / emd.D / (emd.T - 1) * numpy.identity(emd.D)\n",
    "    else:\n",
    "        for i in range(1, emd.T):\n",
    "            lag_one_covariance = emd.sigma_s_lag[i, :]\n",
    "            tmp = emd.theta_s[i, :] - emd.theta_s[i - 1, :]\n",
    "            inv_lmbda += numpy.sum(emd.sigma_s[i]) - \\\n",
    "                         2 * numpy.sum(lag_one_covariance) + \\\n",
    "                         numpy.sum(emd.sigma_s[i - 1]) + \\\n",
    "                         numpy.dot(tmp, tmp)\n",
    "        emd.Q = inv_lmbda / emd.D / (emd.T - 1) * \\\n",
    "                numpy.identity(emd.D)\n",
    "    if stationary == 'all':\n",
    "        emd.Q = numpy.zeros(emd.Q.shape)\n",
    "\n",
    "\n",
    "def m_step_Q2(emd, stationary):\n",
    "    \"\"\"\n",
    "    Computes the optimised state-transition covariance hyperparameters `Q' of\n",
    "    the natural parameters of the posterior distributions over time. Two\n",
    "    different scalars for theta_1 and theta_2 are considered\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    :param stationary:\n",
    "        If 'all' stationary on all thetas is assumed.\n",
    "    \"\"\"\n",
    "    inv_lmbda1 = 0.\n",
    "    inv_lmbda2 = 0.\n",
    "    # Computation for exact case with full covariance matrix\n",
    "    if emd.param_est_eta == 'exact':\n",
    "        for i in range(1, emd.T):\n",
    "            # Loading saved lag-one smoother\n",
    "            lag_one_covariance = emd.sigma_s_lag[i,:,:]\n",
    "            tmp = emd.theta_s[i,:] - emd.theta_s[i-1,:]\n",
    "            inv_lmbda1 += numpy.trace(emd.sigma_s[i,:emd.N,:emd.N]) -\\\n",
    "                     2 * numpy.trace(lag_one_covariance[:emd.N,:emd.N])  +\\\n",
    "                     numpy.trace(emd.sigma_s[i-1,:emd.N,:emd.N])  +\\\n",
    "                     numpy.dot(tmp[:emd.N], tmp[:emd.N])\n",
    "            inv_lmbda2 += numpy.trace(emd.sigma_s[i,emd.N:,emd.N:]) -\\\n",
    "                     2 * numpy.trace(lag_one_covariance[emd.N:,emd.N:])  +\\\n",
    "                     numpy.trace(emd.sigma_s[i-1,emd.N:,emd.N:])  +\\\n",
    "                     numpy.dot(tmp[emd.N:], tmp[emd.N:])\n",
    "\n",
    "        emd.Q[:emd.N,:emd.N] = inv_lmbda1 / emd.N / (emd.T - 1) * numpy.identity(emd.N)\n",
    "        if emd.order > 1:\n",
    "            emd.Q[emd.N:,emd.N:] = inv_lmbda2 / (emd.D - emd.N) / (emd.T - 1) * numpy.identity(emd.D - emd.N)\n",
    "\n",
    "        if stationary == 'all':\n",
    "            emd.Q[:, :] = 0\n",
    "    # Computation for approximate case with diagonal covariance matrix\n",
    "    else:\n",
    "        for i in range(1, emd.T):\n",
    "            # Loading saved lag-one smoother\n",
    "            lag_one_covariance = emd.sigma_s_lag[i, :]\n",
    "            tmp = emd.theta_s[i, :] - emd.theta_s[i - 1, :]\n",
    "            inv_lmbda1 += numpy.sum(emd.sigma_s[i, :emd.N]) - \\\n",
    "                          2 * numpy.sum(lag_one_covariance[:emd.N]) + \\\n",
    "                          numpy.sum(emd.sigma_s[i - 1, :emd.N]) + \\\n",
    "                          numpy.inner(tmp[:emd.N], tmp[:emd.N])\n",
    "            inv_lmbda2 += numpy.sum(emd.sigma_s[i, emd.N:]) - \\\n",
    "                          2 * numpy.sum(lag_one_covariance[emd.N:]) + \\\n",
    "                          numpy.sum(emd.sigma_s[i - 1, emd.N:]) + \\\n",
    "                          numpy.inner(tmp[emd.N:], tmp[emd.N:])\n",
    "\n",
    "        emd.Q[:emd.N, :emd.N] = inv_lmbda1 / emd.N / (emd.T - 1) * \\\n",
    "                                numpy.identity(emd.N)\n",
    "        if emd.order > 1:\n",
    "            emd.Q[emd.N:, emd.N:] = inv_lmbda2 / (emd.D - emd.N) / \\\n",
    "                                    (emd.T - 1) * numpy.identity(emd.D - emd.N)\n",
    "        if stationary == 'all':\n",
    "            emd.Q[:] = 0\n",
    "\n",
    "def m_step_Q3(emd, stationary):\n",
    "    \"\"\"\n",
    "    Computes the optimised state-transition covariance hyperparameters `Q' of\n",
    "    the natural parameters of the posterior distributions over time. For each\n",
    "    individual theta a hyperparameter is considered.\n",
    "    :param container.EMData emd:\n",
    "        All data pertaining to the EM algorithm.\n",
    "    :param stationary:\n",
    "        If 'all' stationary on all thetas is assumed.\n",
    "    \"\"\"\n",
    "    lmbda = numpy.zeros([emd.Q.shape[0]])\n",
    "    # Computation for exact case with full covariance matrix\n",
    "    if emd.param_est_eta == 'exact':\n",
    "        for i in range(1, emd.T):\n",
    "            # Loading saved lag-one smoother\n",
    "            lag_one_covariance = emd.sigma_s_lag[i,:,:]\n",
    "            tmp = emd.theta_s[i,:] - emd.theta_s[i-1,:]\n",
    "            lmbda += numpy.diagonal(emd.sigma_s[i,:,:]) -\\\n",
    "                     2 * numpy.diagonal(lag_one_covariance[:,:]) +\\\n",
    "                     numpy.diagonal(emd.sigma_s[i-1,:,:]) +\\\n",
    "                     tmp**2\n",
    "\n",
    "        if stationary == 'all':\n",
    "            lmbda[:,:] = 0\n",
    "    # Computation for approximate case with diagonal covariance matrix\n",
    "    else:\n",
    "        for i in range(1, emd.T):\n",
    "            # Loading saved lag-one smoother\n",
    "            lag_one_covariance = emd.sigma_s_lag[i]\n",
    "            tmp = emd.theta_s[i,:] - emd.theta_s[i-1,:]\n",
    "            lmbda += emd.sigma_s[i] -\\\n",
    "                     2 * lag_one_covariance  +\\\n",
    "                     emd.sigma_s[i-1]  +\\\n",
    "                     tmp**2\n",
    "\n",
    "        if stationary == 'all':\n",
    "            lmbda[:] = 0\n",
    "\n",
    "    emd.Q = numpy.diag(lmbda / (emd.T - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
